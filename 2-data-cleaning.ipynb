{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5514817",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "from amazon.constants import *\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f124801",
   "metadata": {},
   "source": [
    "`extract_brand()` returns a Polars expression that creates a brand column which holds either the value from store after stripping white spaces or the value from the \"details\" column after removing the 'Brand:'\n",
    "\n",
    "`process_category()` loads the meta and review parquet files into LazyFrames and joins them on parent_asin. It filters rows with valid ratings and non-empty text, adds the brand column using extract_brand(), removes duplicates, and adds a \"year\" column extracted from the timestamp. The cleaned LazyFrame is then saved as a Parquet file in the intermediate folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96733738",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_brand() -> pl.Expr:\n",
    "    store_clean: pl.Then = pl.when(pl.col(\"store\").str.strip_chars() != \"\").then(pl.col(\"store\"))\n",
    "    details_brand: pl.Expr = pl.col(\"details\").str.extract(r\"Brand[:\\s\\-]*([A-Za-z0-9&\\s]+)\", 1)\n",
    "    return pl.coalesce([store_clean, details_brand, pl.lit(\"Unknown\")]).alias(\"brand\")\n",
    "\n",
    "\n",
    "def process_category(category: str) -> None:\n",
    "    lf_review: pl.LazyFrame = pl.scan_parquet(f\"{RAW}/{REVIEW}/{category}.parquet\")\n",
    "    lf_meta: pl.LazyFrame = pl.scan_parquet(f\"{RAW}/{META}/{category}.parquet\")\n",
    "\n",
    "    # a) Merge on parent asin\n",
    "    lf: pl.LazyFrame = lf_review.join(lf_meta, on=\"parent_asin\", how=\"inner\")\n",
    "    \n",
    "    # b) Handle Invalid / Missing Values\n",
    "    lf: pl.LazyFrame = lf.filter(pl.col(\"rating\").is_in([1, 2, 3, 4, 5]))\n",
    "    lf = lf.filter(pl.col(\"text\").str.strip_chars().str.len_chars() > 0)\n",
    "    lf = lf.with_columns([extract_brand()])\n",
    "    \n",
    "    # c) Remove Duplicates\n",
    "    lf = lf.unique(subset=[\"user_id\", \"text\", \"asin\"], keep=\"first\")\n",
    "   \n",
    "    # d) Derived Columns:\n",
    "    lf = lf.with_columns([\n",
    "        pl.col(\"text\").str.count_matches(r\"\\b\\w+\\b\").alias(\"review_length\"),\n",
    "        (pl.col(\"timestamp\").cast(pl.Datetime(\"ms\")).dt.year()).alias(\"year\")\n",
    "    ])\n",
    "\n",
    "    lf.sink_parquet(f\"{INTERMEDIATE}/{category}.parquet\", engine=\"streaming\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f187fa",
   "metadata": {},
   "source": [
    "Process and clean each parquet using the functions detailed above and uses grabage collections freeing up RAM on each iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5053c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "for category in ALL_CATEGORIES:\n",
    "    print(f\"Cleaning dataset for {category}...\")\n",
    "    process_category(category)\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4434f33",
   "metadata": {},
   "source": [
    "After cleaning each category parquet in `ALL_CATEGORIES` the parquets are then loaded into a lazy frame, merged into a singular combined parquet and saved in the processed folder(Gold Layer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1534c91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged: pl.LazyFrame = pl.scan_parquet(f\"{INTERMEDIATE}/*.parquet\")\n",
    "merged = merged.unique(subset=[\"user_id\", \"text\", \"asin\"], keep=\"first\")\n",
    "merged.sink_parquet(\"data/processed/amazon-2023.parquet\", engine=\"streaming\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58831c1",
   "metadata": {},
   "source": [
    "Collated DataFrame was 502,984,947 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7123e392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(502_984_947, 27)\n"
     ]
    }
   ],
   "source": [
    "# (502_984_947, 27)\n",
    "merged.collect(engine=\"streaming\").shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
