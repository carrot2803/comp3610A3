{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8551d8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extension for Scikit-learn* enabled (https://github.com/uxlfoundation/scikit-learn-intelex)\n"
     ]
    }
   ],
   "source": [
    "from sklearnex import patch_sklearn\n",
    "patch_sklearn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87b5f523",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.sparse._matrix import spmatrix\n",
    "from amazon.models import *\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "import joblib\n",
    "from plotly.graph_objs._figure import Figure\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import gc\n",
    "\n",
    "\n",
    "# 1. Download & grab the NLTK stopâ€word list once\n",
    "# nltk.download(\"stopwords\")\n",
    "# STOP_WORDS = set(stopwords.words(\"english\"))\n",
    "# STOP_WORDS.add(\"amazon\")\n",
    "# STOP_WORDS.add(\"Amazon\")\n",
    "# STOP_WORDS.add(\"review\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59992b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop_pattern = r\"\\b(\" + \"|\".join(map(re.escape, STOP_WORDS)) + r\")\\b\"\n",
    "\n",
    "# lf: pl.LazyFrame = (\n",
    "#     pl.scan_parquet(\"data/processed/amazon-2023.parquet\")\n",
    "#       .select([\n",
    "#           pl.col(\"rating\").cast(pl.Int8),\n",
    "#           pl.col(\"text\").cast(pl.Utf8)\n",
    "#       ])\n",
    "#       .with_columns((pl.col(\"rating\") > 3).cast(pl.Int8).alias(\"rating\"))\n",
    "#       .with_columns(\n",
    "#           pl.col(\"text\")\n",
    "#             .str.replace_all(stop_pattern, \"\", literal=False)\n",
    "#             .str.replace_all(r\"\\s+\", \" \", literal=False)  # collapse any gaps left\n",
    "#             .str.strip_chars()\n",
    "#             .alias(\"text\")\n",
    "#       )\n",
    "#       .with_columns(\n",
    "#           pl.col(\"text\")\n",
    "#             .str.replace_all(r\"http\\S+|www\\.\\S+\", \"\", literal=False)\n",
    "#             .str.replace_all(r\"[^\\w\\s]\", \"\", literal=False)\n",
    "#             .str.replace_all(r\"\\s+\", \" \", literal=False)\n",
    "#             .str.to_lowercase()\n",
    "#             .str.strip_chars()\n",
    "#             .str.slice(0, 128)\n",
    "#             .alias(\"text\")\n",
    "#       )\n",
    "#       .filter(pl.col(\"text\").str.len_chars() > 10)\n",
    "# )\n",
    "\n",
    "# lf.sink_parquet(\"data/processed/training.parquet\", engine=\"streaming\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61c09e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df=pl.read_parquet(\"data/processed/training.parquet\", low_memory=True, memory_map=True, use_pyarrow=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8fe5a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X:pl.Series = df[\"text\"]\n",
    "# y: pl.Series = df[\"rating\"]\n",
    "\n",
    "# del df\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a88cbbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(\n",
    "#     X, y, test_size=0.2, random_state=42, shuffle=True\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "885a9b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pl.DataFrame({\"text\": X_train}).write_parquet(\"data/processed/X_train.parquet\")\n",
    "# del X_train\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00a46ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pl.DataFrame({\"rating\": y_train}).write_parquet(\"data/processed/y_train.parquet\")\n",
    "# del y_train\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0aa67da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pl.DataFrame({\"text\": X_test}).write_parquet(\"data/processed/X_test.parquet\")\n",
    "# del X_test\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d412b287",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pl.DataFrame({\"rating\": y_test}).write_parquet(\"data/processed/y_test.parquet\")\n",
    "# del y_test\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7f7a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(\n",
    "    lowercase=True,\n",
    "    token_pattern=r'\\b\\w+\\b', \n",
    "    min_df=5,\n",
    "    max_df=0.8,\n",
    "    stop_words=\"english\"\n",
    ")\n",
    "\n",
    "\n",
    "X_train = pl.read_parquet(\"data/processed/X_train.parquet\",low_memory=True, memory_map=True, use_pyarrow=True)\n",
    "X_train: spmatrix = vectorizer.fit_transform(X_train[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418ac97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = pl.read_parquet(\"data/processed/y_train.parquet\",low_memory=True, memory_map=True, use_pyarrow=True)\n",
    "y_train = y_train[\"rating\"]\n",
    "\n",
    "model = LogisticRegression(max_iter=100) # iter added to stop warning\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c86dc70",
   "metadata": {},
   "outputs": [],
   "source": [
    "del X_train\n",
    "del y_train\n",
    "gc.collect()\n",
    "joblib.dump(model, \"data/logreg_tfidf.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039eb4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorizer = TfidfVectorizer(\n",
    "#     lowercase=True,\n",
    "#     token_pattern=r'\\b\\w+\\b', \n",
    "#     min_df=5,\n",
    "#     max_df=0.8,\n",
    "#     stop_words=\"english\"\n",
    "# )\n",
    "\n",
    "# X_test = pl.read_parquet(\"data/processed/X_test.parquet\",low_memory=True, memory_map=True, use_pyarrow=True)[\"text\"]\n",
    "# X_test: spmatrix = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132efe5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred: np.ndarray = model.predict(X_test)\n",
    "# y_test = pl.read_parquet(\"data/processed/y_test.parquet\",low_memory=True, memory_map=True, use_pyarrow=True)[\"rating\"]\n",
    "\n",
    "\n",
    "# metrics: dict = get_metrics(y_test, y_pred, \"Logistic Regression\")\n",
    "\n",
    "# # F1= 0.919511\n",
    "# # F1= 0.931996\t\n",
    "# # f1_score(y_test, y_pred)\n",
    "# result = pl.DataFrame([metrics])\n",
    "# result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d3d72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig: Figure = plot_confusion_matrix(result)\n",
    "# fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
