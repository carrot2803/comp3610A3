{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c6e676",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import numpy as np\n",
    "import implicit\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "from scipy.sparse import coo_matrix, csr_array\n",
    "from amazon.models import normalize_scores  \n",
    "import random\n",
    "import gc\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19564dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "lf: pl.LazyFrame = pl.scan_parquet(\"data/processed/amazon-2023.parquet\")\n",
    "lf = lf.select([\"user_id\", \"asin\", \"rating\"])\n",
    "lf = lf.filter(pl.len().over(\"user_id\") >= 5)\n",
    "\n",
    "lf = lf.with_columns([\n",
    "    pl.col(\"user_id\").cast(pl.Categorical).alias(\"user_cat\"),\n",
    "    pl.col(\"asin\").cast(pl.Categorical).alias(\"item_cat\")\n",
    "]).drop([\"user_id\", \"asin\"])\n",
    "\n",
    "lf: pl.LazyFrame = lf.with_columns([\n",
    "    pl.col(\"user_cat\").to_physical().alias(\"user_idx\"),\n",
    "    pl.col(\"item_cat\").to_physical().alias(\"item_idx\")\n",
    "])\n",
    "\n",
    "df: pl.DataFrame = lf.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf149f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_users, unique_items = df[\"user_cat\"].unique().sort(), df[\"item_cat\"].unique().sort()\n",
    "\n",
    "user_id_map = {i: user_str for i, user_str in enumerate(unique_users.to_list())}\n",
    "item_id_map = {i: item_str for i, item_str in enumerate(unique_items.to_list())}\n",
    "\n",
    "ratings_np = df['rating'].cast(pl.Float32).to_numpy()\n",
    "user_indices_np = df['user_idx'].to_numpy()\n",
    "item_indices_np = df['item_idx'].to_numpy()\n",
    "\n",
    "num_users, num_items = len(user_id_map), len(item_id_map)\n",
    "train_indices, test_indices = train_test_split(np.arange(len(df)), test_size=0.2, random_state=42)\n",
    "\n",
    "train_user_indices, train_item_indices = user_indices_np[train_indices], item_indices_np[train_indices]\n",
    "train_ratings = ratings_np[train_indices]\n",
    "\n",
    "test_user_indices, test_item_indices = user_indices_np[test_indices], item_indices_np[test_indices]\n",
    "test_ratings = ratings_np[test_indices]\n",
    "\n",
    "del df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f187f3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sparse_csr: csr_array = coo_matrix((train_ratings, (train_user_indices, train_item_indices)),\n",
    "                            shape=(num_users, num_items)).tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb7d317",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = implicit.als.AlternatingLeastSquares(\n",
    "    factors=50, regularization=0.01, iterations=15, random_state=42, use_gpu=False\n",
    ")\n",
    "model.fit(train_sparse_csr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e93c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_ratings_test: list[float] = [\n",
    "    model.user_factors[user_idx, :].dot(model.item_factors[item_idx, :])\n",
    "    for user_idx, item_idx, actual in zip(test_user_indices, test_item_indices, test_ratings)\n",
    "    if user_idx < model.user_factors.shape[0] and item_idx < model.item_factors.shape[0]\n",
    "]\n",
    "\n",
    "if predicted_ratings_test:\n",
    "    rmse: float = root_mean_squared_error(test_ratings[:len(predicted_ratings_test)], predicted_ratings_test)\n",
    "    print(f\"Root-mean-square error (RMSE) on test data = {rmse:.4f}\")\n",
    "else:\n",
    "    print(\"Warning: No test ratings could be predicted.\")\n",
    "    rmse = float('nan')\n",
    "\n",
    "# Root-mean-square error (RMSE) on test data = 4.4926"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6c432e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Demo: Top‑5 recommendations for 3 random test users\n",
    "unique_test_users: np.ndarray = np.unique(test_user_indices)\n",
    "demo_users: list[int] = random.sample(list(unique_test_users), 3)\n",
    "\n",
    "for user_idx in demo_users:\n",
    "    scores = model.user_factors[user_idx].dot(model.item_factors.T)\n",
    "    seen = set(train_item_indices[train_user_indices == user_idx])\n",
    "    scores[list(seen)] = -np.inf  # mask seen\n",
    "\n",
    "    scores: np.ndarray = normalize_scores(scores)\n",
    "    top5_idx: np.ndarray = np.argpartition(scores, -5)[-5:]\n",
    "    top5_idx = top5_idx[np.argsort(-scores[top5_idx])]\n",
    "\n",
    "    print(f\"\\nUser {user_id_map[user_idx]} (idx={user_idx}):\")\n",
    "    for item_idx in top5_idx:\n",
    "        print(f\"  ASIN {item_id_map[item_idx]} — pred. rating {scores[item_idx]:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
